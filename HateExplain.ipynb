{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayushi1722/LLM-Guided-Feature-Extraction-for-HateSpeech-Classification/blob/main/train_eval_naive_hatebert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fJZWjqypSll"
      },
      "outputs": [],
      "source": [
        "! pip install transformers==4.23.1\n",
        "! pip install torch torchvision\n",
        "! pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mzsr3mGI_eB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import AdamW\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "from transformers import AutoModelForTokenClassification, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import BertForTokenClassification, BertForSequenceClassification,BertPreTrainedModel, BertModel\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJsGQFxrovEL",
        "outputId": "74d33515-7597-49db-aa85-e43c5b582b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ]
        }
      ],
      "source": [
        "print(\"CUDA Available: \", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03T-h8ACYt7v"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7oidRv7Yt7v",
        "outputId": "cf717ed1-17cf-493c-a874-9cd95adea8a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54eWRqpW2AwE"
      },
      "outputs": [],
      "source": [
        "## set dataset here\n",
        "# options = [\"gab\", \"twitter\", \"reddit\", \"youtube\"]\n",
        "\n",
        "\n",
        "dataset = \"youtube\"\n",
        "\n",
        "file_map = {\n",
        "    \"gab\": '/content/Rationales_file_GAB_dataset_corrected.csv',\n",
        "    \"twitter\": '/content/Rationales_file_TWITTER_dataset.csv',\n",
        "    \"reddit\": '/content/Rationales_file_REDDIT_dataset.csv',\n",
        "    \"youtube\": '/content/Rationales_file_YOUTUBE_dataset.csv'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu3QBnaoYt7w"
      },
      "outputs": [],
      "source": [
        "file_path = file_map[dataset]\n",
        "# file_path = 'Rationales_file_YOUTUBE_dataset.csv'\n",
        "# file_path = 'Rationales_file_GAB_dataset_corrected.csv'\n",
        "# file_path = 'Rationales_file_TWITTER_dataset.csv'\n",
        "# file_path = 'Rationales_file_REDDIT_dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "train_df = df[df['exp_split'] == 'train']\n",
        "test_df = df[df['exp_split'] == 'test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxLD6WbYbKRB",
        "outputId": "08e29f89-9d5f-4217-8c9a-2fc1123b7173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train df:  29731\n",
            "Test_df:  7433\n"
          ]
        }
      ],
      "source": [
        "print(\"Train df: \", len(train_df))\n",
        "print(\"Test_df: \", len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nieCECDxcKlZ",
        "outputId": "ddb599b5-2745-4237-8650-1fb038b36910"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "# del variables\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFRfebXdrPlg",
        "outputId": "05c978e8-0055-4dfd-b4d4-26a1cef099a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two were not used when initializing BertForSequenceClassification: ['bert_pooler.dense.bias', 'token_classifier.bias', 'token_classifier.weight', 'bert_pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two\")\n",
        "model = hatebert_model = AutoModelForSequenceClassification.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giR4SxPbH_jp"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, texts, labels, tokenizer, max_length):\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    texts = self.texts[idx]\n",
        "    labels = self.labels[idx]\n",
        "    encoding = self.tokenizer(texts, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
        "    # input_ids, mask_ids = torch.tensor(encoding['input_ids']), torch.tensor(encoding['attention_mask'])\n",
        "    input_ids = encoding['input_ids'].squeeze()\n",
        "    attention_mask = encoding['attention_mask'].squeeze()\n",
        "    labels = labels\n",
        "    return input_ids, attention_mask, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFYvQiuzFfJ",
        "outputId": "225ec2fb-0472-4c4a-bf86-e3ec9dae9ca1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters for tuning model initially. Let's see, we will change if required.\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbjfxJqMc7Yt"
      },
      "outputs": [],
      "source": [
        "#Splitting training and validation testing split to test accuracy\n",
        "train_text, val_texts, train_labels, val_labels = train_test_split(train_df['text'].tolist(),train_df['label'].tolist(), test_size = 0.2, random_state = 42)\n",
        "train_dataset = CustomDataset(train_text, train_labels, tokenizer, max_length = 512)\n",
        "val_dataset = CustomDataset(val_texts, val_labels, tokenizer, max_length = 512)\n",
        "\n",
        "#Creating dataloader object to train the model\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PQbpEJ3Yt70"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMG59qBiYt70",
        "outputId": "c30118a8-0c54-4c5b-9c8b-8c97439b495b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "# del variables\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx9zCWKarK13",
        "outputId": "9156b2cb-1c8b-4a9b-f781-576bfc115fae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 11892/11892 [43:46<00:00,  4.53it/s, accuracy=0.865, loss=0.0122]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Validation Accuracy: 0.9045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  67%|██████▋   | 7950/11892 [29:19<14:31,  4.52it/s, accuracy=0.946, loss=0.782]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracy = 0\n",
        "    train_epoch_size = 0\n",
        "\n",
        "    with tqdm(train_dataloader, desc=f'Epoch {epoch + 1}', dynamic_ncols=True) as loop:\n",
        "      for batch in loop:\n",
        "          input_ids, mask_ids, labels = batch\n",
        "          if torch.cuda.is_available():\n",
        "              input_ids = input_ids.to(device)\n",
        "              mask_ids = mask_ids.to(device)\n",
        "              labels = labels.to(device)\n",
        "          # optimizer.grad()\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(input_ids=input_ids, attention_mask=mask_ids, labels=labels)\n",
        "          loss = outputs.loss\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_losses.append(loss.item())\n",
        "\n",
        "          # Update accuracy and epoch size\n",
        "          predictions = torch.argmax(outputs.logits, dim=1)\n",
        "          train_accuracy += (predictions == labels).sum().item()\n",
        "          train_epoch_size += len(labels)\n",
        "\n",
        "          # Update tqdm progress bar with set_postfix\n",
        "          loop.set_postfix(loss=loss.item(), accuracy=train_accuracy / train_epoch_size)\n",
        "\n",
        "\n",
        "    # Evaluating on Validation task\n",
        "    model.eval()\n",
        "\n",
        "    val_predictions = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids, mask_ids, labels = batch\n",
        "            if torch.cuda.is_available():\n",
        "                input_ids = input_ids.to(device)\n",
        "                mask_ids = mask_ids.to(device)\n",
        "                labels = labels.to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=mask_ids)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "            val_predictions.extend(predictions.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(val_predictions, val_labels)\n",
        "    print(f\"Epoch {epoch + 1}: Validation Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EabT3TLIzSx3"
      },
      "outputs": [],
      "source": [
        "torch.save(model, f'fine_tuned_naive_hateexplain_{dataset}.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVBoJnMrYt72"
      },
      "source": [
        "# Testing on Tests Dataset for accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA71SvcgzS0X"
      },
      "outputs": [],
      "source": [
        "test_texts = test_df['text'].tolist()\n",
        "test_labels = test_df['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8qdQ_siYt73"
      },
      "outputs": [],
      "source": [
        "test_dataset = CustomDataset(test_texts, test_labels, tokenizer, max_length = 512)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzWaSlHgYt74"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids, mask_ids, labels = batch\n",
        "        if torch.cuda.is_available():\n",
        "                input_ids = input_ids.to(device)\n",
        "                mask_ids = mask_ids.to(device)\n",
        "                labels = labels.to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=mask_ids)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        test_predictions.extend(predictions.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(test_predictions, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR_tY9NYYt74",
        "outputId": "b007f577-bec5-4eab-bc84-fd60b9c9d913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of test dataset: 0.6743762993762994\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy of test dataset:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkNHQw2FYt74"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}